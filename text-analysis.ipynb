{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdaab25-03ec-476b-a92a-d40a7ba0c741",
   "metadata": {},
   "source": [
    "# Loading the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e288bd-c54a-42cf-bbc3-0e8304499cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"miracle_in_the_andes.txt\", \"r\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50971eeb-ee35-4f5c-9738-5a5c4aa83073",
   "metadata": {},
   "source": [
    "# the most used words(non-article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f57ece3-1513-4fad-9eaf-78f12ddaa419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter', 'before', 'it', 'was', 'friday']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern,book.lower())\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281e9913-d700-4029-85d3-1b9a922d37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for word in findings:\n",
    "    if word in d.keys():\n",
    "        d[word] = d[word] + 1\n",
    "    else:\n",
    "        d[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a990a6-2efc-402d-8e2e-3af954b0b332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to'), (2060, 'of')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list = [(value, key) for (key, value) in d.items()]\n",
    "d_list = sorted(d_list, reverse = True)\n",
    "d_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95149faf-2d3f-412c-a890-7e3b2fcbba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2024.4.16-cp310-cp310-macosx_11_0_arm64.whl (291 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.0 nltk-3.8.1 regex-2024.4.16 tqdm-4.66.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.10 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0a9e52-7151-4d25-95db-6567e38662ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/meg/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13073971-b81e-4363-bd87-b4159387dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_words.append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebddea71-a6c7-41ae-9627-c6210ff1d1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 575),\n",
       " ('us', 519),\n",
       " ('said', 292),\n",
       " ('roberto', 284),\n",
       " ('could', 252),\n",
       " ('one', 249),\n",
       " ('snow', 227),\n",
       " ('mountain', 183),\n",
       " ('time', 182),\n",
       " ('like', 165)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bd652-5787-46f7-99f3-729eef94634b",
   "metadata": {},
   "source": [
    "# Sentiment analysis: what is the most positive and the most negative chapter?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
